import aiohttp
import asyncio
import aiofiles
import json
import uvicorn
import logging
import time
import os
import numpy as np
import re
import pickle
from pathlib import Path
from fastapi import FastAPI, HTTPException, Form, UploadFile, File
from sentence_transformers import SentenceTransformer, CrossEncoder
from rank_bm25 import BM25Okapi
from voicerecognise import recognize_audio_with_sdk
from yandex_cloud_ml_sdk import YCloudML
from typing import Dict, List, Optional
import faiss


logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)


BASE_DIR = "base"
EMBEDDINGS_DIR = "embeddings_data"
os.makedirs(BASE_DIR, exist_ok=True)
os.makedirs(EMBEDDINGS_DIR, exist_ok=True)
API_URL = "https://dev.back.matrixcrm.ru/api/v1/AI/servicesByFilters" 
YANDEX_FOLDER_ID = "b1gnq2v60fut60hs9vfb" 
YANDEX_API_KEY = "AQVNw5Kg0jXoaateYQWdSr2k8cbst_y4_WcbvZrW"

logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
search_model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
logger.info("–ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")

conversation_history: Dict[str, Dict] = {}

app = FastAPI()


def get_tenant_path(tenant_id: str) -> Path:
    """–°–æ–∑–¥–∞–µ—Ç –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Ç–µ–Ω–∞–Ω—Ç–∞."""
    tenant_path = Path(EMBEDDINGS_DIR) / tenant_id
    tenant_path.mkdir(parents=True, exist_ok=True)
    return tenant_path


def normalize_text(text: str) -> str:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç: —É–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã, –ø—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É."""
    text = text.strip()
    text = re.sub(r"[^\w\s\d\n]", "", text) 
    return text.lower()


def tokenize_text(text: str) -> List[str]:
    """–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç: —Ä–∞–∑–±–∏–≤–∞–µ—Ç –Ω–∞ —Å–ª–æ–≤–∞, —É–¥–∞–ª—è–µ—Ç —Å—Ç–æ–ø-—Å–ª–æ–≤–∞."""
    stopwords = {
        "–∏", "–≤", "–Ω–∞", "—Å", "–ø–æ", "–¥–ª—è", "–∫–∞–∫", "—á—Ç–æ", "—ç—Ç–æ", "–Ω–æ",
        "–∞", "–∏–ª–∏", "—É", "–æ", "–∂–µ", "–∑–∞", "–∫", "–∏–∑", "–æ—Ç", "—Ç–∞–∫", "—Ç–æ", "–≤—Å–µ"
    }
    tokens = text.split()
    return [word for word in tokens if word not in stopwords]


def extract_text_fields(record: dict) -> str:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è –∏–∑ –∑–∞–ø–∏—Å–∏ (—Å–ª–æ–≤–∞—Ä—è) –∏ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É –¥–ª—è –∏–Ω–¥–µ–∫—Å–∞—Ü–∏–∏."""
    filial = record.get("filialName", "–§–∏–ª–∏–∞–ª –Ω–µ —É–∫–∞–∑–∞–Ω")
    category = record.get("categoryName", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞")
    service = record.get("serviceName", "–£—Å–ª—É–≥–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞")
    service_desc = record.get("serviceDescription", "–û–ø–∏—Å–∞–Ω–∏–µ —É—Å–ª—É–≥–∏ –Ω–µ —É–∫–∞–∑–∞–Ω–æ")
    price = record.get("price", "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞")
    specialist = record.get("employeeFullName", "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –Ω–µ —É–∫–∞–∑–∞–Ω")
    spec_desc = record.get("employeeDescription", "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ")
    text = (
        f"–§–∏–ª–∏–∞–ª: {filial}\n"
        f"–ö–∞—Ç–µ–≥–æ—Ä–∏—è: {category}\n"
        f"–£—Å–ª—É–≥–∞: {service}\n"
        f"–û–ø–∏—Å–∞–Ω–∏–µ —É—Å–ª—É–≥–∏: {service_desc}\n"
        f"–¶–µ–Ω–∞: {price}\n"
        f"–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç: {specialist}\n"
        f"–û–ø–∏—Å–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞: {spec_desc}"
    )
    return normalize_text(text)


async def load_json_data(tenant_id: str) -> List[dict]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON-—Ñ–∞–π–ª–∞ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ tenant_id."""
    file_path = os.path.join(BASE_DIR, f"{tenant_id}.json")
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail=f"–§–∞–π–ª –¥–ª—è tenant_id={tenant_id} –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    async with aiofiles.open(file_path, "r", encoding="utf-8") as f:
        content = await f.read()
        data = json.loads(content)

    records = []
    branches = data.get("data", {}).get("branches", [])
    for branch in branches:
        filial_name = branch.get("name", "–§–∏–ª–∏–∞–ª –Ω–µ —É–∫–∞–∑–∞–Ω")
        categories = branch.get("categories", [])
        for category in categories:
            category_name = category.get("name", "–ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞")
            services = category.get("services", [])
            for service in services:
                service_name = service.get("name", "–£—Å–ª—É–≥–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞")
                price = service.get("price", "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞")
                service_description = service.get("description", "")
                employees = service.get("employees", [])
                if employees:
                    for emp in employees:
                        employee_full_name = emp.get("full_name", "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –Ω–µ —É–∫–∞–∑–∞–Ω")
                        employee_description = emp.get("description", "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ")
                        record = {
                            "filialName": filial_name,
                            "categoryName": category_name,
                            "serviceName": service_name,
                            "serviceDescription": service_description,
                            "price": price,
                            "employeeFullName": employee_full_name,
                            "employeeDescription": employee_description
                        }
                        records.append(record)
                else:
                    record = {
                        "filialName": filial_name,
                        "categoryName": category_name,
                        "serviceName": service_name,
                        "serviceDescription": service_description,
                        "price": price,
                        "employeeFullName": "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –Ω–µ —É–∫–∞–∑–∞–Ω",
                        "employeeDescription": "–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ"
                    }
                    records.append(record)
    return records


async def prepare_data(tenant_id: str):
    """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –ø–æ–∏—Å–∫–∞: –∑–∞–≥—Ä—É–∂–∞–µ—Ç, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç, —Å—Ç—Ä–æ–∏—Ç –∏–Ω–¥–µ–∫—Å—ã."""
    tenant_path = get_tenant_path(tenant_id)
    data_file = tenant_path / "data.json"
    embeddings_file = tenant_path / "embeddings.npy"
    bm25_file = tenant_path / "bm25.pkl"
    faiss_index_file = tenant_path / "faiss_index.index"

    
    if all([f.exists() for f in [data_file, embeddings_file, bm25_file, faiss_index_file]]):
        file_age = time.time() - os.path.getmtime(data_file)
        if file_age < 2_592_000: 
           
            async with aiofiles.open(data_file, "r", encoding="utf-8") as f:
                data = json.loads(await f.read())
            embeddings = np.load(embeddings_file)
            with open(bm25_file, "rb") as f:
                bm25 = pickle.load(f)
            index = faiss.read_index(str(faiss_index_file))
            return data, embeddings, bm25, index

    records = await load_json_data(tenant_id)
    documents = [extract_text_fields(record) for record in records]

    loop = asyncio.get_event_loop()
   
    embeddings, bm25 = await asyncio.gather(
        loop.run_in_executor(None, lambda: search_model.encode(documents, convert_to_tensor=True).cpu().numpy()),
        loop.run_in_executor(None, lambda: BM25Okapi([tokenize_text(doc) for doc in documents]))
    )


    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings)

    
    faiss.write_index(index, str(faiss_index_file))
    async with aiofiles.open(data_file, "w", encoding="utf-8") as f:
        await f.write(json.dumps({
            "records": records,
            "raw_texts": documents,
            "timestamp": time.time()
        }, ensure_ascii=False, indent=4))
    np.save(embeddings_file, embeddings)
    with open(bm25_file, "wb") as f:
        pickle.dump(bm25, f)

    return {"records": records, "raw_texts": documents}, embeddings, bm25, index


async def update_json_file(mydtoken: str, tenant_id: str):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç JSON-—Ñ–∞–π–ª —Å –¥–∞–Ω–Ω—ã–º–∏, –ø–æ–ª—É—á–∞—è –∏—Ö —Å –≤–Ω–µ—à–Ω–µ–≥–æ API."""
    tenant_path = get_tenant_path(tenant_id)
    file_path = os.path.join(BASE_DIR, f"{tenant_id}.json")

    
    if os.path.exists(file_path):
        file_age = time.time() - os.path.getmtime(file_path)
        if file_age < 2_592_000:  
            logger.info(f"–§–∞–π–ª {file_path} –∞–∫—Ç—É–∞–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ.")
            return

    for f in tenant_path.glob("*"):
        try:
            os.remove(f)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {f}: {e}")


    try:
        async with aiohttp.ClientSession() as session:
            headers = {"Authorization": f"Bearer {mydtoken}"}
            params = {"tenantId": tenant_id, "page": 1}
            all_data = []
            max_pages = 500  

            while True:
                if params["page"] > max_pages:
                    logger.info(f"–î–æ—Å—Ç–∏–≥–Ω—É—Ç –ª–∏–º–∏—Ç {max_pages} —Å—Ç—Ä–∞–Ω–∏—Ü, –∑–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É.")
                    break

                async with session.get(API_URL, headers=headers, params=params) as response:
                    response.raise_for_status()  
                    data = await response.json()

                    branches = data.get("data", {}).get("branches", [])
                    if not branches:
                        logger.info(f"–°—Ç—Ä–∞–Ω–∏—Ü–∞ {params['page']} –ø—É—Å—Ç–∞—è, –∑–∞–≤–µ—Ä—à–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É.")
                        break

                    all_data.extend(branches)
                    logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(branches)} –∑–∞–ø–∏—Å–µ–π —Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã {params['page']}.")
                    params["page"] += 1

            logger.info(f"–û–±—â–µ–µ —á–∏—Å–ª–æ –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö —Ñ–∏–ª–∏–∞–ª–æ–≤: {len(all_data)}")

            
            async with aiofiles.open(file_path, "w", encoding="utf-8") as json_file:
                await json_file.write(json.dumps(
                    {"code": data.get("code", 200), "data": {"branches": all_data}},
                    ensure_ascii=False,
                    indent=4
                ))

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.")


async def rerank_with_cross_encoder(query: str, candidates: List[int], raw_texts: List[str]) -> List[int]:
    """–ü–µ—Ä–µ—Ä–∞–Ω–∂–∏—Ä—É–µ—Ç –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞) —Å –ø–æ–º–æ—â—å—é CrossEncoder."""
    cross_inp = [(query, raw_texts[idx]) for idx in candidates]
    loop = asyncio.get_event_loop()
    cross_scores = await loop.run_in_executor(None, lambda: cross_encoder.predict(cross_inp))
    sorted_indices = np.argsort(cross_scores)[::-1].tolist()  # –°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é
    return [candidates[i] for i in sorted_indices]


# –û–ø–∏—Å–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è YandexGPT (JSON Schema)
free_times_function = {
    "name": "getFreeTimesOfEmployeeByChoosenServices",
    "description": "–ü–æ–ª—É—á–∏—Ç—å —Å–≤–æ–±–æ–¥–Ω–æ–µ –≤—Ä–µ–º—è —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º —É—Å–ª—É–≥–∞–º",
    "parameters": {
        "type": "object",
        "properties": {
            "employeeId": {"type": "string", "description": "ID —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞"},
            "serviceId": {"type": "array", "items": {"type": "string"}, "description": "–°–ø–∏—Å–æ–∫ ID —É—Å–ª—É–≥"},
            "dateTime": {"type": "string", "description": "–î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD"},
            "tenantId": {"type": "string", "description": "ID —Ç–µ–Ω–∞–Ω—Ç–∞"},
            "filialId": {"type": "string", "description": "ID —Ñ–∏–ª–∏–∞–ª–∞"},
            "langId": {"type": "string", "description": "–Ø–∑—ã–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, ru)"}
        },
        "required": ["employeeId", "serviceId", "dateTime", "tenantId", "filialId", "langId"]
    }
}


async def generate_yandexgpt_response(context: str, history: List[dict], question: str, tools: Optional[List[dict]] = None):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º YandexGPT, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –≤—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–π.

    Args:
        context: –ö–æ–Ω—Ç–µ–∫—Å—Ç (—Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞).
        history: –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞.
        question: –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        tools: –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π (JSON Schema).

    Returns:
        –ö–æ—Ä—Ç–µ–∂ (—Ç–µ–∫—Å—Ç –æ—Ç–≤–µ—Ç–∞, –æ–±—ä–µ–∫—Ç –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–∏) –∏–ª–∏ (None, None), –µ—Å–ª–∏ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞.
    """
    system_prompt = """üîπ –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏ üîπ

–¢—ã ‚Äì –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–ª–∏–Ω–∏–∫–∏ MED YU MED –ø–æ –∏–º–µ–Ω–∏ –ê–∏–¥–∞. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äì –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –Ω–∞—Ö–æ–¥–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞—Ö, —É—Å–ª—É–≥–∞—Ö, —Ñ–∏–ª–∏–∞–ª–∞—Ö –∏ —Ü–µ–Ω–∞—Ö. –£ —Ç–µ–±—è –µ—Å—Ç—å –¥–æ—Å—Ç—É–ø –∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞—Ö, —É—Å–ª—É–≥–∞—Ö, —Ü–µ–Ω–∞—Ö, —Ñ–∏–ª–∏–∞–ª–∞—Ö. –¢—ã –º–æ–∂–µ—à—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ–±–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (—Ñ—É–Ω–∫—Ü–∏–∏), —á—Ç–æ–±—ã –ø–æ–ª—É—á–∞—Ç—å –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

## ‚è∞ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–ø–∏—Å–∏ –∏ —Å–≤–æ–±–æ–¥–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –Ω—É–∂–Ω–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–ø–∏—Å–∏ –Ω–∞ –ø—Ä–∏–µ–º, —Å–≤–æ–±–æ–¥–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤ –∏–ª–∏ –¥–∞—Ç–∞—Ö, —Ç—ã **–¥–æ–ª–∂–Ω–∞** –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `getFreeTimesOfEmployeeByChoosenServices`.  –≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç —Ç–µ–±–µ –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.  –ù–µ –ø—ã—Ç–∞–π—Å—è —É–≥–∞–¥–∞—Ç—å —Å–≤–æ–±–æ–¥–Ω–æ–µ –≤—Ä–µ–º—è ‚Äì –∏—Å–ø–æ–ª—å–∑—É–π —Ñ—É–Ω–∫—Ü–∏—é!

**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ñ—É–Ω–∫—Ü–∏–∏ `getFreeTimesOfEmployeeByChoosenServices`:**

*   `employeeId`: ID —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ).  –¢—ã –º–æ–∂–µ—à—å –Ω–∞–π—Ç–∏ ID —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
*   `serviceId`: –°–ø–∏—Å–æ–∫ ID —É—Å–ª—É–≥ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ). –¢—ã –º–æ–∂–µ—à—å –Ω–∞–π—Ç–∏ ID —É—Å–ª—É–≥ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
*   `dateTime`: –î–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ YYYY-MM-DD (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ).  –£—Ç–æ—á–Ω–∏ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–∞—Ç—É, –µ—Å–ª–∏ –æ–Ω –µ—ë –Ω–µ —É–∫–∞–∑–∞–ª.
*   `tenantId`: ID —Ç–µ–Ω–∞–Ω—Ç–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ).
*   `filialId`: ID —Ñ–∏–ª–∏–∞–ª–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ).  –¢—ã –º–æ–∂–µ—à—å –Ω–∞–π—Ç–∏ ID —Ñ–∏–ª–∏–∞–ª–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.
*   `langId`: –Ø–∑—ã–∫ (–Ω–∞–ø—Ä–∏–º–µ—Ä, "ru") (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ).

**–ü—Ä–∏–º–µ—Ä:** –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç "–ú–æ–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –∫ –∫–æ—Å–º–µ—Ç–æ–ª–æ–≥—É –ò–≤–∞–Ω–æ–≤—É –Ω–∞ —á–∏—Å—Ç–∫—É –ª–∏—Ü–∞ –≤ —Å–ª–µ–¥—É—é—â—É—é —Å—Ä–µ–¥—É?", —Ç—ã –¥–æ–ª–∂–Ω–∞:
  1. –ù–∞–π—Ç–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ ID –∫–æ—Å–º–µ—Ç–æ–ª–æ–≥–∞ –ò–≤–∞–Ω–æ–≤–∞.
  2. –ù–∞–π—Ç–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ ID —É—Å–ª—É–≥–∏ "—á–∏—Å—Ç–∫–∞ –ª–∏—Ü–∞".
  3. –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–∞—Ç—É "—Å–ª–µ–¥—É—é—â–µ–π —Å—Ä–µ–¥—ã" (–Ω–∞–ø—Ä–∏–º–µ—Ä, 2024-03-06).
  4. –í—ã–∑–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `getFreeTimesOfEmployeeByChoosenServices` —Å —ç—Ç–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.

## üîç –ü–æ–¥–±–æ—Ä —É—Å–ª—É–≥

–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ —É—Å–ª—É–≥–∏, —Ç—ã –æ–±—è–∑–∞–Ω–∞:

*   –ù–∞–π—Ç–∏ –≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —É—Å–ª—É–≥–∏.
*   –£–∫–∞–∑–∞—Ç—å —Ü–µ–Ω—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, "–æ—Ç 12000 —Ä—É–±–ª–µ–π üí∏").
*   –ù–∞–∑–≤–∞—Ç—å —Ñ–∏–ª–∏–∞–ª, –≥–¥–µ –¥–æ—Å—Ç—É–ø–Ω–∞ —É—Å–ª—É–≥–∞ (–ú–æ—Å–∫–≤–∞ ‚Äì –•–æ–¥—ã–Ω–∫–∞, –ú–æ—Å–∫–≤–∞ ‚Äì –°–∏—Ç–∏, –î—É–±–∞–π).
*   –ü–µ—Ä–µ—á–∏—Å–ª–∏—Ç—å –≤—Å–µ—Ö —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–ø–æ–ª–Ω—è—é—Ç —ç—Ç—É —É—Å–ª—É–≥—É (–±–µ–∑ —Å–ª–æ–≤ "–∏ –¥—Ä—É–≥–∏–µ", —Ç–æ–ª—å–∫–æ –ø–æ–ª–Ω—ã–µ —Å–ø–∏—Å–∫–∏!).
*   –û–±—ä—è—Å–Ω–∏—Ç—å –ø–æ–ª—å–∑—É —É—Å–ª—É–≥–∏ –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–≠—Ç–∞ –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ –ø–æ–º–æ–∂–µ—Ç —É–±—Ä–∞—Ç—å –º–æ—Ä—â–∏–Ω—ã –∏ —Å–¥–µ–ª–∞—Ç—å –∫–æ–∂—É –±–æ–ª–µ–µ —É–ø—Ä—É–≥–æ–π ‚ú®").

## ‚ùå –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç

–ï—Å–ª–∏ —Ç—ã –Ω–µ –º–æ–∂–µ—à—å –Ω–∞–π—Ç–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å (–¥–∞–∂–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Ñ—É–Ω–∫—Ü–∏–π), —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å. –ù–µ –≤—ã–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é!

## üí¨ –ö–∞–∫ –≤–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥

*   –ü–∏—à–∏ –∂–∏–≤–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –∏–∑–±–µ–≥–∞—è –∫–∞–Ω—Ü–µ–ª—è—Ä–∏–∑–º–æ–≤.
*   –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ —É–º–µ—Ä–µ–Ω–Ω–æ, –ø–æ —Å–º—ã—Å–ª—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, "üí∏" –¥–ª—è —Ü–µ–Ω, "üóì" –¥–ª—è –∑–∞–ø–∏—Å–∏).
*   –£—á–∏—Ç—ã–≤–∞–π –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ ‚Äì –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É—Ç–æ—á–Ω—è–µ—Ç –¥–µ—Ç–∞–ª–∏, —Ç—ã –¥–æ–ª–∂–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –æ—Ç–≤–µ—Ç—ã.
*   –ü—Ä–æ—è–≤–ª—è–π —ç–º–ø–∞—Ç–∏—é: –µ—Å–ª–∏ —á–µ–ª–æ–≤–µ–∫ –¥–µ–ª–∏—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–æ–π, –ø–æ–∫–∞–∂–∏, —á—Ç–æ –ø–æ–Ω–∏–º–∞–µ—à—å –µ–≥–æ —Å–∏—Ç—É–∞—Ü–∏—é.
*   –ü–∏—à–∏ –≤—Å–µ —Ü–µ–Ω—ã –Ω–∞ —É—Å–ª—É–≥–∏ —Å –ø—Ä–µ–¥–ª–æ–≥–æ–º "–æ—Ç".

## üö® –û—Å–æ–±—ã–µ —É–∫–∞–∑–∞–Ω–∏—è

*   –í –∫–ª–∏–Ω–∏–∫–µ —Ç—Ä–∏ —Ñ–∏–ª–∏–∞–ª–∞: –ú–æ—Å–∫–≤–∞ (–•–æ–¥—ã–Ω–∫–∞, –°–∏—Ç–∏), –î—É–±–∞–π (Bluewaters).
*   –ï—Å–ª–∏ —É—Å–ª—É–≥–∞/—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ñ–∏–ª–∏–∞–ª—É, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∑—ã–≤–∞–π —ç—Ç–æ.
*   –ù–µ –ø–∏—à–∏ "–î–æ–±—Ä—ã–π –¥–µ–Ω—å" –ø–æ–≤—Ç–æ—Ä–Ω–æ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞.
*   –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—â–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, –¥–∞–∂–µ –µ—Å–ª–∏ —Ä–∞–Ω–µ–µ –¥–∞–≤–∞–ª –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç.
*  –ù–µ –ø—Ä–µ–¥–ª–∞–≥–∞–π —É—Å–ª—É–≥–∏, –µ—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —ç—Ç–æ —è–≤–Ω–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ.

## üí° –û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤
* –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É—Ç–æ—á–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã.
* –ü—Ä–∏ –ø–æ–∏—Å–∫–µ —É—Ç–æ—á–Ω—è—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π –∫–∞–∫ —Å—Ç–∞—Ä—ã–µ, —Ç–∞–∫ –∏ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.

"""

    messages = [
        {"role": "system", "text": system_prompt},
        {"role": "system", "text": f"–í–æ—Ç —Å–ø–∏—Å–æ–∫ 10 —É—Å–ª—É–≥:\n{context}\n"}
    ]

    for entry in history[-10:]:
        messages.append({"role": "user", "text": entry['user_query']})
        messages.append({"role": "assistant", "text": entry.get('assistant_response', '')})  

    messages.append({"role": "user", "text": question})

    try:
        loop = asyncio.get_event_loop()
        sdk = YCloudML(folder_id=YANDEX_FOLDER_ID, auth=YANDEX_API_KEY)
        model_uri = f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-32k/rc"

        request_data = {
            "model_uri": model_uri,
            "completion_options": {
                "stream": False,
                "temperature": 0.55,
                "max_tokens": 1000
            },
            "messages": messages
        }
        if tools:
            request_data["tools"] = tools

        result = await loop.run_in_executor(
            None,
            lambda: sdk.models.completions(**request_data)  # –ü–µ—Ä–µ–¥–∞–µ–º –∫–∞–∫ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã
        )

        if result and result.alternatives:
            message = result.alternatives[0].message
            if message.role == "assistant" and message.text:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç.
                return message.text.strip(), None  
            elif message.role == 'assistant' and message.tool_calls:
                return None, message.tool_calls[0]  
            else:  
                return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –º–Ω–µ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç.", None
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –º–Ω–µ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç.", None 
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ YandexGPT API: {str(e)}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.", None  


async def call_external_function(tool_call, mydtoken, tenant_id) -> str:
    """
    –í—ã–∑—ã–≤–∞–µ—Ç –≤–Ω–µ—à–Ω—é—é —Ñ—É–Ω–∫—Ü–∏—é (API) –Ω–∞ –æ—Å–Ω–æ–≤–µ tool_call.

    Args:
        tool_call: –û–±—ä–µ–∫—Ç –≤—ã–∑–æ–≤–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –æ—Ç YandexGPT.
        mydtoken: –¢–æ–∫–µ–Ω –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏.
        tenant_id: ID —Ç–µ–Ω–∞–Ω—Ç–∞.

    Returns:
        –†–µ–∑—É–ª—å—Ç–∞—Ç –≤—ã–∑–æ–≤–∞ API –≤ –≤–∏–¥–µ JSON-—Å—Ç—Ä–æ–∫–∏.
    """
    if tool_call.function.name == "getFreeTimesOfEmployeeByChoosenServices":
        arguments = json.loads(tool_call.function.arguments)
        employee_id = arguments["employeeId"]
        service_ids = arguments["serviceId"]
        date_time = arguments["dateTime"]
        # tenant_id = arguments["tenantId"]  # –£–∂–µ –µ—Å—Ç—å –≤ –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö
        filial_id = arguments["filialId"]
        lang_id = arguments["langId"]

        # –ó–¥–µ—Å—å –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∞–ª—å–Ω—ã–π –≤—ã–∑–æ–≤  API –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏.
        #  –ü—Ä–∏–º–µ—Ä (–∑–∞–≥–ª—É—à–∫–∞):
        async with aiohttp.ClientSession() as session:
            headers = {"Authorization": f"Bearer {mydtoken}"}  
            api_url = "https://dev.back.matrixcrm.ru/api/v1/AI/getFreeTimesOfEmployeeByChoosenServices"  
            data = {
                "employeeId": employee_id,
                "serviceId": service_ids,
                "dateTime": date_time,
                "tenantId": tenant_id,
                "filialId": filial_id,
                "langId": lang_id
            }

            try:
                async with session.post(api_url, headers=headers, json=data) as response:
                    response.raise_for_status()  
                    result = await response.json()
                   
                    return json.dumps({"free_times": result.get("free_times", [])})  

            except aiohttp.ClientError as e:
                logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ API: {e}")
                return json.dumps({"error": "–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ API"})  
    else:
        return json.dumps({"error": f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è: {tool_call.function.name}"})


@app.post("/ask")
async def ask_assistant(
    user_id: str = Form(...),
    question: Optional[str] = Form(None),
    mydtoken: str = Form(...),
    tenant_id: str = Form(...),
    file: UploadFile = File(None)
):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –∑–∞–ø—Ä–æ—Å–æ–≤ –∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç—É."""
    try:

        current_time = time.time()
        expired_users = [uid for uid, data in conversation_history.items() if
                         current_time - data["last_active"] > 2592000]  
        for uid in expired_users:
            del conversation_history[uid]


        recognized_text = None
        if file and file.filename:
            temp_path = f"/tmp/{file.filename}"
            try:
                async with aiofiles.open(temp_path, "wb") as temp_file:
                    await temp_file.write(await file.read())
                loop = asyncio.get_event_loop()
                recognized_text = await loop.run_in_executor(None, lambda: recognize_audio_with_sdk(temp_path))
            finally:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
            if not recognized_text:
                raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏–∑ —Ñ–∞–π–ª–∞.")

        
        input_text = recognized_text or question
        if not input_text:
            raise HTTPException(status_code=400, detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–¥–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–ª–∏ —Ñ–∞–π–ª.")

        
        tools = [{"type": "function", "function": free_times_function}]

     
        if user_id not in conversation_history:
            conversation_history[user_id] = {"history": [], "last_active": time.time(), "greeted": False}
        conversation_history[user_id]["last_active"] = time.time()

       
        data_file_path = get_tenant_path(tenant_id) / "data.json"
        if not data_file_path.exists():
            await update_json_file(mydtoken, tenant_id)  

        
        data_dict, embeddings, bm25, faiss_index = await prepare_data(tenant_id)

    
        normalized_question = normalize_text(input_text)
        tokenized_query = tokenize_text(normalized_question)

        
        bm25_scores = bm25.get_scores(tokenized_query)
        top_bm25_indices = np.argsort(bm25_scores)[::-1][:50].tolist()

    
        loop = asyncio.get_event_loop()
        query_embedding = await loop.run_in_executor(
            None,
            lambda: search_model.encode(normalized_question, convert_to_tensor=True).cpu().numpy()
        )
        D, I = faiss_index.search(query_embedding.reshape(1, -1), 50)
        DISTANCE_THRESHOLD = 1.0 
        filtered_faiss = [idx for idx, dist in zip(I[0].tolist(), D[0].tolist()) if dist < DISTANCE_THRESHOLD]
        if not filtered_faiss:
            filtered_faiss = I[0].tolist()
        top_faiss_indices = filtered_faiss


        combined_indices = list(set(top_bm25_indices + top_faiss_indices))[:50]

        top_10_indices = await rerank_with_cross_encoder(
            query=normalized_question,
            candidates=combined_indices[:30],
            raw_texts=data_dict["raw_texts"]
        )

        context = "\n\n".join([
            f"**–î–æ–∫—É–º–µ–Ω—Ç {i + 1}:**\n"
            f"* –§–∏–ª–∏–∞–ª: {data_dict['records'][idx].get('filialName', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n"
            f"* –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {data_dict['records'][idx].get('categoryName', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}\n"
            f"* –£—Å–ª—É–≥–∞: {data_dict['records'][idx].get('serviceName', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')}\n"
            f"* –¶–µ–Ω–∞: {data_dict['records'][idx].get('price', '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞')} —Ä—É–±.\n"
            f"* –°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç: {data_dict['records'][idx].get('employeeFullName', '–ù–µ —É–∫–∞–∑–∞–Ω')}\n"
            f"* –û–ø–∏—Å–∞–Ω–∏–µ: {data_dict['records'][idx].get('employeeDescription', '–û–ø–∏—Å–∞–Ω–∏–µ –Ω–µ —É–∫–∞–∑–∞–Ω–æ')}"
            for i, idx in enumerate(top_10_indices[:5])
        ])
        response_text, tool_call = await generate_yandexgpt_response(
            context, conversation_history[user_id]["history"], input_text, tools=tools
        )

        if tool_call:
            function_result = await call_external_function(tool_call, mydtoken, tenant_id)

            messages = [
                {"role": "system", "text": "–¢—ã ‚Äì –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–ª–∏–Ω–∏–∫–∏ MED YU MED –ø–æ –∏–º–µ–Ω–∏ –ê–∏–¥–∞..."}, 
                {"role": "system", "text": f"–í–æ—Ç —Å–ø–∏—Å–æ–∫ 10 —É—Å–ª—É–≥:\n{context}\n"},
            ]
            for entry in conversation_history[user_id]["history"][-10:]:
                messages.append({"role": "user", "text": entry['user_query']})
                messages.append({"role": "assistant", "text": entry.get("assistant_response", "")})  

            messages.append({"role": "user", "text": input_text})  
            messages.append(  
                {
                    "role": "assistant",
                    "tool_calls": [
                        {
                            "id": tool_call.id,
                            "type": tool_call.type,
                            "function": {
                                "name": tool_call.function.name,
                                "arguments": tool_call.function.arguments
                            }
                        }
                    ]
                }
            )
            messages.append({ 
                "role": "tool",
                "content": function_result,
                "tool_call_id": tool_call.id

            })

            response_text, _ = await generate_yandexgpt_response(context, [], "", tools=tools)  # –ü—É—Å—Ç–∞—è –∏—Å—Ç–æ—Ä–∏—è –∏ –∑–∞–ø—Ä–æ—Å.
            if response_text: 
                conversation_history[user_id]["history"].append({
                    "user_query": input_text,
                    "assistant_response": response_text,
                    "search_results": [data_dict['records'][idx] for idx in top_10_indices]
                })
                return {"response": response_text}
            else: 
                return {"response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞."}

        elif response_text:
            conversation_history[user_id]["history"].append({
                "user_query": input_text,
                "assistant_response": response_text,
                "search_results": [data_dict['records'][idx] for idx in top_10_indices]
            })
            return {"response": response_text}
        else:
            return {"response": "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞."}



    except FileNotFoundError as e:  
        logger.error(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {e}", exc_info=True)
        raise HTTPException(status_code=404, detail=f"–î–∞–Ω–Ω—ã–µ –¥–ª—è tenant_id={tenant_id} –Ω–µ –Ω–∞–π–¥–µ–Ω—ã.")
    except aiohttp.ClientError as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ –≤–Ω–µ—à–Ω–µ–º—É API: {e}", exc_info=True)
        raise HTTPException(status_code=503, detail="–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –≤–Ω–µ—à–Ω–µ–º—É —Å–µ—Ä–≤–∏—Å—É.")
    except Exception as e:
        logger.error(f"–ù–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {str(e)}")

if __name__ == "__main__":
    logger.info("–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ –ø–æ—Ä—Ç—É 8001...")
    uvicorn.run(app, host="0.0.0.0", port=8001)
