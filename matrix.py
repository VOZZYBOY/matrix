import asyncio
import aiohttp
import aiofiles
import json
import uvicorn
import logging
import time
import os
import numpy as np
import re
from pathlib import Path
from fastapi import FastAPI, HTTPException, Form, UploadFile, File
from sentence_transformers import SentenceTransformer, CrossEncoder
from voicerecognise import recognize_audio_with_sdk
from yandex_cloud_ml_sdk import YCloudML
from typing import Dict, List, Optional
import faiss

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# –ü—É—Ç–∏ –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö
BASE_DIR = "base"
EMBEDDINGS_DIR = "embeddings_data"
os.makedirs(BASE_DIR, exist_ok=True)
os.makedirs(EMBEDDINGS_DIR, exist_ok=True)

# URL API –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è JSON (–µ—Å–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è)
API_URL = "https://dev.back.matrixcrm.ru/api/v1/AI/servicesByFilters"

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã Yandex Cloud
YANDEX_FOLDER_ID = "b1gnq2v60fut60hs9vfb"
YANDEX_API_KEY = "AQVNw5Kg0jXoaateYQWdSr2k8cbst_y4_WcbvZrW"

logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π...")
search_model = SentenceTransformer("sentence-transformers/paraphrase-multilingual-mpnet-base-v2")
cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
logger.info("–ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")


conversation_history: Dict[str, Dict] = {}

app = FastAPI()

def get_tenant_path(tenant_id: str) -> Path:
    """–°–æ–∑–¥–∞–µ—Ç –ø–∞–ø–∫—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ç–µ–Ω–∞–Ω—Ç–∞."""
    tenant_path = Path(EMBEDDINGS_DIR) / tenant_id
    tenant_path.mkdir(parents=True, exist_ok=True)
    return tenant_path

def normalize_text(text: str) -> str:
    """–ü—Ä–∏–≤–æ–¥–∏—Ç —Ç–µ–∫—Å—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É –∏ —É–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã."""
    text = text.lower().strip()
    text = re.sub(r"[^\w\s\d]", "", text)
    return text

def extract_text_fields(record: dict) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä–æ–∫—É –¥–ª—è —Å–µ—Ä–≤–∏—Å–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ:
    "–§–∏–ª–∏–∞–ª ‚Äì –ö–∞—Ç–µ–≥–æ—Ä–∏—è ‚Äì –£—Å–ª—É–≥–∞ ‚Äì –¶–µ–Ω–∞ ‚Äì –°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç: –æ–ø–∏—Å–∞–Ω–∏–µ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞".
    
    –ï—Å–ª–∏ —É —Å–µ—Ä–≤–∏—Å–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤, –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è –≤—Å–µ —Å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª–µ–º "; ".
    """
    branch = record.get("branch", "–ù–µ —É–∫–∞–∑–∞–Ω —Ñ–∏–ª–∏–∞–ª")
    category = record.get("category", "–ù–µ —É–∫–∞–∑–∞–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è")
    service_name = record.get("name", "–ù–µ —É–∫–∞–∑–∞–Ω–∞ —É—Å–ª—É–≥–∞")
    price = record.get("price", "–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞")
    
 
    employees = record.get("employees", [])
    emp_info = []
    for emp in employees:
        full_name = emp.get("full_name", "–ù–µ —É–∫–∞–∑–∞–Ω —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç")
        description = emp.get("description", "").strip() or "–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç"
        emp_info.append(f"{full_name}: {description}")
    
    employees_str = "; ".join(emp_info) if emp_info else "–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã –Ω–µ —É–∫–∞–∑–∞–Ω—ã"
    full_text = f"{branch} - {category} - {service_name} - {price} —Ä—É–±. - {employees_str}"
    return normalize_text(full_text)

async def load_json_data(tenant_id: str) -> List[dict]:
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ JSON-—Ñ–∞–π–ª–∞ —Å —É—á–µ—Ç–æ–º –≤–ª–æ–∂–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã:
    branches -> categories -> services.
    –î–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–µ—Ä–≤–∏—Å–∞ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –ø–æ–ª—è "branch" –∏ "category".
    """
    file_path = os.path.join(BASE_DIR, f"{tenant_id}.json")
    if not os.path.exists(file_path):
        raise HTTPException(status_code=404, detail=f"–§–∞–π–ª –¥–ª—è tenant_id={tenant_id} –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    
    async with aiofiles.open(file_path, "r", encoding="utf-8") as f:
        content = await f.read()
        data = json.loads(content)
        
        branches = data.get("data", {}).get("branches", [])
        records = []
        for branch in branches:
            branch_name = branch.get("name", "–ù–µ —É–∫–∞–∑–∞–Ω —Ñ–∏–ª–∏–∞–ª")
            if "categories" in branch:
                for category in branch["categories"]:
                    category_name = category.get("name", "–ù–µ —É–∫–∞–∑–∞–Ω–∞ –∫–∞—Ç–µ–≥–æ—Ä–∏—è")
                    if "services" in category:
                        for service in category["services"]:
                            service["branch"] = branch_name
                            service["category"] = category_name
                            records.append(service)
        return records

async def prepare_data(tenant_id: str):
    """
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏–ª–∏ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ–Ω–∞–Ω—Ç–∞:
      - –ó–∞–≥—Ä—É–∂–∞–µ—Ç JSON –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∑–∞–ø–∏—Å–∏ –≤ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å –ø–æ–º–æ—â—å—é extract_text_fields.
      - –í—ã—á–∏—Å–ª—è–µ—Ç —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏ —Å—Ç—Ä–æ–∏—Ç FAISS-–∏–Ω–¥–µ–∫—Å.
    """
    tenant_path = get_tenant_path(tenant_id)
    data_file = tenant_path / "data.json"
    embeddings_file = tenant_path / "embeddings.npy"
    faiss_index_file = tenant_path / "faiss_index.index"
    
    if all([f.exists() for f in [data_file, embeddings_file, faiss_index_file]]):
        file_age = time.time() - os.path.getmtime(data_file)
        if file_age < 2_592_000:  # 30 –¥–Ω–µ–π
            async with aiofiles.open(data_file, "r") as f:
                data = json.loads(await f.read())
            embeddings = np.load(embeddings_file)
            index = faiss.read_index(str(faiss_index_file))
            return data, embeddings, index

    records = await load_json_data(tenant_id)
    documents = [extract_text_fields(record) for record in records]
    
    loop = asyncio.get_event_loop()
    embeddings = await loop.run_in_executor(
        None,
        lambda: search_model.encode(documents, convert_to_tensor=True).cpu().numpy()
    )
    dimension = embeddings.shape[1]
    index = faiss.IndexFlatL2(dimension)
    index.add(embeddings)
    faiss.write_index(index, str(faiss_index_file))
    
    async with aiofiles.open(data_file, "w") as f:
        await f.write(json.dumps({"records": records, "raw_texts": documents, "timestamp": time.time()}))
    np.save(embeddings_file, embeddings)
    
    return {"records": records, "raw_texts": documents}, embeddings, index

async def update_json_file(mydtoken: str, tenant_id: str):
    """–û–±–Ω–æ–≤–ª—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏ —É–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —Ñ–∞–π–ª—ã, –µ—Å–ª–∏ –æ–Ω–∏ —É—Å—Ç–∞—Ä–µ–ª–∏."""
    tenant_path = get_tenant_path(tenant_id)
    file_path = os.path.join(BASE_DIR, f"{tenant_id}.json")
    if os.path.exists(file_path):
        file_age = time.time() - os.path.getmtime(file_path)
        if file_age < 2_592_000:
            logger.info(f"–§–∞–π–ª {file_path} –∞–∫—Ç—É–∞–ª–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ.")
            return
    for f in tenant_path.glob("*"):
        try:
            os.remove(f)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è —Ñ–∞–π–ª–∞ {f}: {e}")
    try:
        async with aiohttp.ClientSession() as session:
            headers = {"Authorization": f"Bearer {mydtoken}"}
            params = {"tenantId": tenant_id, "page": 1}
            all_data = []
            while True:
                async with session.get(API_URL, headers=headers, params=params) as response:
                    response.raise_for_status()
                    data = await response.json()
                    items = data.get("data", {}).get("items", [])
                    if not items:
                        break
                    all_data.extend(items)
                    logger.info(f"–ü–æ–ª—É—á–µ–Ω–æ {len(items)} –∑–∞–ø–∏—Å–µ–π —Å —Å—Ç—Ä–∞–Ω–∏—Ü—ã {params['page']}.")
                    params["page"] += 1
            async with aiofiles.open(file_path, "w", encoding="utf-8") as json_file:
                await json_file.write(json.dumps({"data": {"items": all_data}}, ensure_ascii=False, indent=4))
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞: {str(e)}")
        raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö.")

async def rerank_with_cross_encoder(query: str, candidates: List[int], raw_texts: List[str]) -> List[int]:
    """
    –†–µ—Ä–∞–Ω–∫–∏–Ω–≥ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫—Ä–æ—Å—Å-—ç–Ω–∫–æ–¥–µ—Ä–∞.
    –î–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã (query, –¥–æ–∫—É–º–µ–Ω—Ç) –≤—ã—á–∏—Å–ª—è–µ–º –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏.
    """
    cross_inp = [(query, raw_texts[idx]) for idx in candidates]
    loop = asyncio.get_event_loop()
    cross_scores = await loop.run_in_executor(
        None,
        lambda: cross_encoder.predict(cross_inp)
    )
    sorted_indices = np.argsort(cross_scores)[::-1].tolist()
    return [candidates[i] for i in sorted_indices]

async def generate_yandexgpt_response(context: str, history: List[dict], question: str) -> str:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º YandexGPT.
    –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –≤–∫–ª—é—á–∞–µ—Ç –ø–æ–¥—Ä–æ–±–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (—Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ —Ñ–∏–ª–∏–∞–ª–µ, —É—Å–ª—É–≥–µ, —Ü–µ–Ω–µ, —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞—Ö)
    –∏ –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞, —á—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –º–æ–¥–µ–ª–∏ —É—á–∏—Ç—ã–≤–∞—Ç—å –∫–∞–∫ –Ω–æ–≤—ã–µ, —Ç–∞–∫ –∏ —Ä–∞–Ω–µ–µ –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    """
    system_prompt = """
üîπ **–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏** üîπ

**–¢—ã ‚Äì –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–ª–∏–Ω–∏–∫–∏ MED YU MED.** –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äì –ø–æ–º–æ–≥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –Ω–∞—Ö–æ–¥–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞—Ö, —É—Å–ª—É–≥–∞—Ö, —Ñ–∏–ª–∏–∞–ª–∞—Ö –∏ —Ü–µ–Ω–∞—Ö. –¢—ã —Ä–∞–±–æ—Ç–∞–µ—à—å –∫–∞–∫ **RAG-–º–æ–¥–µ–ª—å (Retrieval-Augmented Generation)**, —á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ:

1. **–í–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω** ‚Äì –≤ –Ω—ë–º –µ—Å—Ç—å –ø–æ–¥—Ä–æ–±–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞—Ö, —É—Å–ª—É–≥–∞—Ö, —Ü–µ–Ω–∞—Ö –∏ —Ñ–∏–ª–∏–∞–ª–∞—Ö. –≠—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ.

2. **–¢–µ–±–µ –Ω–µ –Ω—É–∂–Ω–æ –≤—ã–¥—É–º—ã–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é** ‚Äì –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, –ø—Ä—è–º–æ —Å–æ–æ–±—â–∞–π –æ–± —ç—Ç–æ–º. 

3. **–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É—Ç–æ—á–Ω—è–µ—Ç –∑–∞–ø—Ä–æ—Å**, —Ç—ã –æ–±—è–∑–∞–Ω–∞ –∏—Å–∫–∞—Ç—å –æ—Ç–≤–µ—Ç –∏–º–µ–Ω–Ω–æ –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ, –∞ –Ω–µ —Ç–æ–ª—å–∫–æ –≤ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–∞. 

## üìå **1. –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞**

- –ü—Ä–æ—á–∏—Ç–∞–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏ –ø–æ–π–º–∏, –∫ —á–µ–º—É –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∑–∞–ø—Ä–æ—Å: **—É—Å–ª—É–≥–∏**, **—Ü–µ–Ω—ã**, **—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã**, **—Ñ–∏–ª–∏–∞–ª—ã** –∏ —Ç. –¥.
- –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å –Ω–µ—è—Å–µ–Ω ‚Äì **–∑–∞–¥–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å** –≤–º–µ—Å—Ç–æ —Ç–æ–≥–æ, —á—Ç–æ–±—ã –¥–æ–≥–∞–¥—ã–≤–∞—Ç—å—Å—è.

## üîç **2. –ü–æ–¥–±–æ—Ä —É—Å–ª—É–≥**

–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ —É—Å–ª—É–≥–∏, —Ç—ã –æ–±—è–∑–∞–Ω–∞:
- –ù–∞–π—Ç–∏ **–≤—Å–µ –ø–æ–¥—Ö–æ–¥—è—â–∏–µ —É—Å–ª—É–≥–∏**.
- –£–∫–∞–∑–∞—Ç—å **—Ü–µ–Ω—É** (–Ω–∞–ø—Ä–∏–º–µ—Ä, `"–æ—Ç 12000 —Ä—É–±–ª–µ–π üí∏"`).
- –ù–∞–∑–≤–∞—Ç—å **—Ñ–∏–ª–∏–∞–ª**, –≥–¥–µ –¥–æ—Å—Ç—É–ø–Ω–∞ —É—Å–ª—É–≥–∞ (**–ú–æ—Å–∫–≤–∞ ‚Äì –•–æ–¥—ã–Ω–∫–∞, –ú–æ—Å–∫–≤–∞ ‚Äì –°–∏—Ç–∏, –î—É–±–∞–π**).
- –ü–µ—Ä–µ—á–∏—Å–ª–∏—Ç—å **–≤—Å–µ—Ö —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤**, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–ø–æ–ª–Ω—è—é—Ç —ç—Ç—É —É—Å–ª—É–≥—É (**–±–µ–∑ —Å–ª–æ–≤ "–∏ –¥—Ä—É–≥–∏–µ", —Ç–æ–ª—å–∫–æ –ø–æ–ª–Ω—ã–µ —Å–ø–∏—Å–∫–∏!**).
- –û–±—ä—è—Å–Ω–∏—Ç—å **–ø–æ–ª—å–∑—É —É—Å–ª—É–≥–∏** –≤ 1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö (–Ω–∞–ø—Ä–∏–º–µ—Ä: `"–≠—Ç–∞ –ø—Ä–æ—Ü–µ–¥—É—Ä–∞ –ø–æ–º–æ–∂–µ—Ç —É–±—Ä–∞—Ç—å –º–æ—Ä—â–∏–Ω—ã –∏ —Å–¥–µ–ª–∞—Ç—å –∫–æ–∂—É –±–æ–ª–µ–µ —É–ø—Ä—É–≥–æ–π ‚ú®"`).

## üìç **3. –ï—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ**

- –ß–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏, —á—Ç–æ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç, –∏ –ø—Ä–µ–¥–ª–æ–∂–∏ —É—Ç–æ—á–Ω–∏—Ç—å –∑–∞–ø—Ä–æ—Å.
- **–ü—Ä–∏–º–µ—Ä:** `"–ü–æ–∫–∞ –Ω–µ –Ω–∞—à–ª–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –Ω–æ –º–æ–≥—É –ø–æ–º–æ—á—å, –µ—Å–ª–∏ —É—Ç–æ—á–Ω–∏—à—å –¥–µ—Ç–∞–ª–∏ üòä"`.

## üéØ **4. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞**

- –ï—Å–ª–∏ —É–º–µ—Å—Ç–Ω–æ, **–ø—Ä–µ–¥–ª–æ–∂–∏ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è** (`"–•–æ—á–µ—à—å –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –Ω–∞ —É–¥–æ–±–Ω–æ–µ –≤—Ä–µ–º—è? üóì"`).
- –ó–∞–∫–∞–Ω—á–∏–≤–∞–π –¥—Ä—É–∂–µ–ª—é–±–Ω–æ, –Ω–æ **–Ω–µ –ø–µ—Ä–µ–≥—Ä—É–∂–∞–π –æ—Ç–≤–µ—Ç —ç–º–æ–¥–∑–∏**.

## üí¨ **5. –ö–∞–∫ –≤–µ—Å—Ç–∏ –¥–∏–∞–ª–æ–≥**

- **–ü–∏—à–∏ –∂–∏–≤–æ –∏ –¥—Ä—É–∂–µ–ª—é–±–Ω–æ**, –∏–∑–±–µ–≥–∞—è –∫–∞–Ω—Ü–µ–ª—è—Ä–∏–∑–º–æ–≤.
- –ò—Å–ø–æ–ª—å–∑—É–π **—ç–º–æ–¥–∑–∏ —É–º–µ—Ä–µ–Ω–Ω–æ**, –ø–æ —Å–º—ã—Å–ª—É (–Ω–∞–ø—Ä–∏–º–µ—Ä, `"üí∏"` –¥–ª—è —Ü–µ–Ω, `"üóì"` –¥–ª—è –∑–∞–ø–∏—Å–∏).
- **–£—á–∏—Ç—ã–≤–∞–π –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞** ‚Äì –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É—Ç–æ—á–Ω—è–µ—Ç –¥–µ—Ç–∞–ª–∏, —Ç—ã –¥–æ–ª–∂–Ω–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –æ—Ç–≤–µ—Ç—ã.
- **–ü—Ä–æ—è–≤–ª—è–π —ç–º–ø–∞—Ç–∏—é**: –µ—Å–ª–∏ —á–µ–ª–æ–≤–µ–∫ –¥–µ–ª–∏—Ç—Å—è –ø—Ä–æ–±–ª–µ–º–æ–π, –ø–æ–∫–∞–∂–∏, —á—Ç–æ –ø–æ–Ω–∏–º–∞–µ—à—å –µ–≥–æ —Å–∏—Ç—É–∞—Ü–∏—é.

## üö® **6. –û—Å–æ–±—ã–µ —É–∫–∞–∑–∞–Ω–∏—è**

- –í –∫–ª–∏–Ω–∏–∫–µ —Ç—Ä–∏ —Ñ–∏–ª–∏–∞–ª–∞: **–ú–æ—Å–∫–≤–∞ (–•–æ–¥—ã–Ω–∫–∞, –°–∏—Ç–∏), –î—É–±–∞–π** (Bluewaters).
- –î–µ—Ä–∂–∏ –≤–µ—Å—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø–∞–º—è—Ç–∏, —Ç–∞–∫ –∫–∞–∫ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –∑–∞–¥–∞–≤–∞—Ç—å –º–Ω–æ–≥–æ —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.
- –ï—Å–ª–∏ —É—Å–ª—É–≥–∞/—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–º—É —Ñ–∏–ª–∏–∞–ª—É, **–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É–∫–∞–∑—ã–≤–∞–π —ç—Ç–æ**.
- **–ù–µ –ø–∏—à–∏ "–î–æ–±—Ä—ã–π –¥–µ–Ω—å" –ø–æ–≤—Ç–æ—Ä–Ω–æ –≤ —Ä–∞–º–∫–∞—Ö –æ–¥–Ω–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞**.
- **–ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø—Ä–æ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞**, –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ **–∏—â–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ**, –¥–∞–∂–µ –µ—Å–ª–∏ —Ä–∞–Ω–µ–µ –¥–∞–≤–∞–ª –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç.

## ‚ö†Ô∏è **7. –ì–ª–∞–≤–Ω–æ–µ –ø—Ä–∞–≤–∏–ª–æ**

–¢—ã ‚Äì **RAG-–º–æ–¥–µ–ª—å**, –∏ –≤—Å—ë, —á—Ç–æ —Ç–µ–±–µ –Ω—É–∂–Ω–æ, —É–∂–µ –µ—Å—Ç—å –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç, **–Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π** ‚Äì –ª—É—á—à–µ —Å–ø—Ä–æ—Å–∏ —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å. –ù–µ –ø—Ä–µ–¥–ª–∞–≥–∞–π —É—Å–ª—É–≥–∏, –µ—Å–ª–∏ –≤ –≤–æ–ø—Ä–æ—Å–µ —ç—Ç–æ —è–≤–Ω–æ –Ω–µ —É–∫–∞–∑–∞–Ω–æ.

## üí° **8. –û–±—Ä–∞–±–æ—Ç–∫–∞ —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤**

- –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É—Ç–æ—á–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –ø–æ—Å—Ç–∞—Ä–∞–π—Å—è **–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å—Ç–∞—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ**, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –±—ã–ª–∏ –ø–æ–ª—É—á–µ–Ω—ã.
- –í—Å–µ–≥–¥–∞ **–ø—Ä–æ–≤–µ—Ä—è–π –∫–æ–Ω—Ç–µ–∫—Å—Ç**, –ø—Ä–µ–∂–¥–µ —á–µ–º –æ—Ç–≤–µ—á–∞—Ç—å. –£–±–µ–¥–∏—Å—å, —á—Ç–æ —Ç—ã –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ—à—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∞ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ —É–∂–µ –±—ã–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã —Ä–∞–Ω–µ–µ.
- **–ü—Ä–∏ –ø–æ–∏—Å–∫–µ —É—Ç–æ—á–Ω—è—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤** –∏—Å–ø–æ–ª—å–∑—É–π –∫–∞–∫ —Å—Ç–∞—Ä—ã–µ, —Ç–∞–∫ –∏ –Ω–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ.

## üìù **–ü—Ä–∏–º–µ—Ä**

–ö–æ–Ω—Ç–µ–∫—Å—Ç:
{context}

–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
{question}

–¢—ã ‚Äì –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –∫–ª–∏–Ω–∏–∫–∏. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äì –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å —Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ü–æ–Ω–∏–º–∞–π, —á—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã, –∏ –æ—Ç–≤–µ—á–∞–π –∏—Å—Ö–æ–¥—è –∏–∑ —Ç–æ–≥–æ, —á—Ç–æ —É–∂–µ –±—ã–ª–æ —Å–∫–∞–∑–∞–Ω–æ. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É—á–∏—Ç—ã–≤–∞–π –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.
"""

    messages = [{"role": "system", "text": system_prompt}]
    
    for entry in history[-10:]:
        messages.append({"role": "user", "text": entry['user_query']})
        messages.append({"role": "assistant", "text": entry['assistant_response']})
    messages.append({"role": "user", "text": question})
    
    try:
        loop = asyncio.get_event_loop()
        sdk = YCloudML(folder_id=YANDEX_FOLDER_ID, auth=YANDEX_API_KEY)
        model_uri = f"gpt://{YANDEX_FOLDER_ID}/yandexgpt-32k/rc"
        result = await loop.run_in_executor(
            None,
            lambda: sdk.models.completions(model_uri)
                        .configure(temperature=0.5, max_tokens=4096)
                        .run(messages)
        )
        if result and result.alternatives:
            return result.alternatives[0].text.strip()
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –º–Ω–µ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç."
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ YandexGPT API: {str(e)}")
        return "–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞."

@app.post("/ask")
async def ask_assistant(
    user_id: str = Form(...),
    question: Optional[str] = Form(None),
    mydtoken: str = Form(...),
    tenant_id: str = Form(...),
    file: UploadFile = File(None)
):
    try:
        
        current_time = time.time()
        expired_users = [uid for uid, data in conversation_history.items() if current_time - data["last_active"] > 1800]
        for uid in expired_users:
            del conversation_history[uid]
    
        recognized_text = None
        if file and file.filename:
            temp_path = f"/tmp/{file.filename}"
            try:
                async with aiofiles.open(temp_path, "wb") as temp_file:
                    await temp_file.write(await file.read())
                loop = asyncio.get_event_loop()
                recognized_text = await loop.run_in_executor(
                    None,
                    lambda: recognize_audio_with_sdk(temp_path)
                )
            finally:
                if os.path.exists(temp_path):
                    os.remove(temp_path)
            if not recognized_text:
                raise HTTPException(status_code=500, detail="–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è —Ä–µ—á–∏ –∏–∑ —Ñ–∞–π–ª–∞.")
    
        input_text = recognized_text or question
        if not input_text:
            raise HTTPException(status_code=400, detail="–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –ø–µ—Ä–µ–¥–∞—Ç—å —Ç–µ–∫—Å—Ç –∏–ª–∏ —Ñ–∞–π–ª.")
    
        force_update = False
        if force_update or not (get_tenant_path(tenant_id) / "data.json").exists():
            await update_json_file(mydtoken, tenant_id)
    
        data_dict, _ , faiss_index = await prepare_data(tenant_id)
    
        normalized_question = normalize_text(input_text)
        loop = asyncio.get_event_loop()
        query_embedding = await loop.run_in_executor(
            None,
            lambda: search_model.encode(normalized_question, convert_to_tensor=True).cpu().numpy()
        )
        D, I = faiss_index.search(query_embedding.reshape(1, -1), 50)
        distance_threshold = 0.4
        filtered_candidates = [I[0][i] for i in range(len(D[0])) if D[0][i] < distance_threshold]
        if not filtered_candidates:
            filtered_candidates = I[0].tolist()
    
        top_10_indices = (await rerank_with_cross_encoder(
            query=normalized_question,
            candidates=filtered_candidates,
            raw_texts=data_dict["raw_texts"]
        ))[:10]
    
        
        current_context = "\n".join([
            f"{i+1}. {data_dict['records'][idx].get('branch', '–§–∏–ª–∏–∞–ª –Ω–µ —É–∫–∞–∑–∞–Ω')} - "
            f"{data_dict['records'][idx].get('category', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è –Ω–µ —É–∫–∞–∑–∞–Ω–∞')} - "
            f"{data_dict['records'][idx].get('name', '–£—Å–ª—É–≥–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞')} - "
            f"{data_dict['records'][idx].get('price', '–¶–µ–Ω–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞')} —Ä—É–±. - "
            f"–°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã: {', '.join([emp.get('full_name', '–ù–µ —É–∫–∞–∑–∞–Ω') + ': ' + (emp.get('description', '') or '–û–ø–∏—Å–∞–Ω–∏–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç') for emp in data_dict['records'][idx].get('employees', [])])}"
            for i, idx in enumerate(top_10_indices)
        ])
    
       
        if user_id not in conversation_history:
            conversation_history[user_id] = {
                "history": [],
                "accumulated_context": "",  
                "last_active": time.time(),
                "greeted": False
            }
        conversation_history[user_id]["last_active"] = time.time()
    
       
        accumulated_context = conversation_history[user_id].get("accumulated_context", "")
        if accumulated_context:
            full_context = accumulated_context + "\n" + current_context
        else:
            full_context = current_context
        
        conversation_history[user_id]["accumulated_context"] = full_context
    
        response_text = await generate_yandexgpt_response(
            context=full_context,
            history=conversation_history[user_id]["history"],
            question=input_text
        )
    
        conversation_history[user_id]["history"].append({
            "user_query": input_text,
            "assistant_response": response_text,
            "search_results": [data_dict['records'][idx] for idx in top_10_indices],
            "context": current_context
        })
    
        return {"response": response_text}
    
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}")

if __name__ == "__main__":
    logger.info("–ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ –Ω–∞ –ø–æ—Ä—Ç—É 8001...")
    uvicorn.run(app, host="0.0.0.0", port=8001)
