"""
–ú–æ–¥—É–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –∫–ª–∏–Ω–∏–∫–∏.
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç LLM –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞–∫–æ–Ω—á–µ–Ω–Ω—ã–º –∏–ª–∏ –Ω–µ–ø–æ–ª–Ω—ã–º.
"""

import logging
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import time
import re

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import BaseMessage, messages_from_dict
from pydantic import BaseModel, Field
from langchain_openai import ChatOpenAI

logger = logging.getLogger(__name__)

class CompletenessStatus(str, Enum):
    """–°—Ç–∞—Ç—É—Å –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    COMPLETE = "complete"      
    INCOMPLETE = "incomplete"      

class MessageAnalysis(BaseModel):
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è"""
    status: CompletenessStatus = Field(description="–°—Ç–∞—Ç—É—Å –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è")
    confidence: float = Field(description="–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –≤ –æ—Ü–µ–Ω–∫–µ (0.0-1.0)", ge=0.0, le=1.0)
    reasoning: str = Field(description="–û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ —Ä–µ—à–µ–Ω–∏—è")
    suggested_wait_time: float = Field(description="–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–µ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö", ge=0.0, le=30.0)
    indicators: List[str] = Field(description="–ö–ª—é—á–µ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã, –ø–æ–≤–ª–∏—è–≤—à–∏–µ –Ω–∞ —Ä–µ—à–µ–Ω–∏–µ")

@dataclass
class MessageContext:
    """–ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
    current_message: str
    previous_messages: List[str]
    user_id: str
    time_since_last_message: Optional[float] = None
    conversation_topic: Optional[str] = None

class MessageCompletenessAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º OpenAI o3-mini"""
    
    def __init__(self, openai_api_key: str, model_name: str = "o3-mini"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
        
        Args:
            openai_api_key: API –∫–ª—é—á OpenAI
            model_name: –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è (o3-mini –∏–ª–∏ gpt-4o-mini)
        """
        base_llm = ChatOpenAI(
            model=model_name,
            api_key=openai_api_key,
            max_tokens=2000, 
            timeout=20      
          
        )
        
      
        self.llm = base_llm.with_structured_output(MessageAnalysis)
        
        
        self.prompt_template = ChatPromptTemplate.from_messages([
            ("system", self._get_system_prompt()),
            ("human", "{analysis_request}")
        ])
        self._analysis_cache: Dict[str, Tuple[MessageAnalysis, float]] = {}
        self._cache_ttl = 60.0
        
    def _get_system_prompt(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏ –∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏"""
        return """–¢—ã - —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –º–µ–¥–∏—Ü–∏–Ω—Å–∫–æ–π –∫–ª–∏–Ω–∏–∫–µ.

–ó–ê–î–ê–ß–ê: –û–ø—Ä–µ–¥–µ–ª–∏, –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏–ª–∏ –Ω—É–∂–Ω–æ –∂–¥–∞—Ç—å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è.

–ü–†–ò–ù–¶–ò–ü–´ –ê–ù–ê–õ–ò–ó–ê:
1. –ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–µ—á—å –ë–ï–ó –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è = –ù–û–†–ú–ê–õ–¨–ù–û –∏ –ó–ê–í–ï–†–®–ï–ù–û
2. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∞—è –ø–æ–ª–Ω–æ—Ç–∞ –≤–∞–∂–Ω–µ–µ –≥—Ä–∞–º–º–∞—Ç–∏–∫–∏  
3. –ü—Ä–∏ —Å–æ–º–Ω–µ–Ω–∏—è—Ö –≤—ã–±–∏—Ä–∞–π COMPLETE (–ª—É—á—à–µ –æ—Ç–≤–µ—Ç–∏—Ç—å, —á–µ–º –∑–∞—Å—Ç–∞–≤–∏—Ç—å –∂–¥–∞—Ç—å)
4. –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã –æ–±—ã—á–Ω–æ –ø—Ä–æ—Å—Ç—ã–µ –∏ –ø—Ä—è–º—ã–µ
5. –£–ß–ò–¢–´–í–ê–ô –ö–û–ù–¢–ï–ö–°–¢ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏

–¢–û–õ–¨–ö–û –î–í–ê –°–¢–ê–¢–£–°–ê:
- COMPLETE: –º—ã—Å–ª—å –≤—ã—Ä–∞–∂–µ–Ω–∞ –ø–æ–ª–Ω–æ—Å—Ç—å—é, –º–æ–∂–Ω–æ –æ—Ç–≤–µ—á–∞—Ç—å
- INCOMPLETE: —è–≤–Ω–æ –æ–±—Ä—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –ø–æ–ª—É—Å–ª–æ–≤–µ, –Ω—É–∂–Ω–æ –∂–¥–∞—Ç—å –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è

–ü–†–ò–ú–ï–†–´ –ó–ê–í–ï–†–®–ï–ù–ù–´–• (–±–µ–∑ –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è):
‚úÖ "–ø–æ–¥—Å–∫–∞–∂–∏ –≥–¥–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –∞–º–±—É–ª–∞—Ç–æ—Ä–∏—è" 
‚úÖ "—É –º–µ–Ω—è –±–æ–ª–∏—Ç –≥–æ–ª–æ–≤–∞"
‚úÖ "–Ω—É–∂–Ω–æ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –∫ –≤—Ä–∞—á—É"  
‚úÖ "–∫–æ–≥–¥–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç–µ"
‚úÖ "—Å–∫–æ–ª—å–∫–æ —Å—Ç–æ–∏—Ç –ø—Ä–∏–µ–º"
‚úÖ "–º–æ–∂–Ω–æ –ø—Ä–∏–π—Ç–∏ –∑–∞–≤—Ç—Ä–∞"
‚úÖ "—Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ –∫–ª–∏–Ω–∏–∫–∞"
‚úÖ "–≥–¥–µ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤–∞—à–∞ –±–æ–ª—å–Ω–∏—Ü–∞"
‚úÖ "—Ö–æ—á—É —É–∑–Ω–∞—Ç—å —Ä–∞—Å–ø–∏—Å–∞–Ω–∏–µ –≤—Ä–∞—á–µ–π"
‚úÖ "–ø—Ä–∏–Ω–∏–º–∞–µ—Ç–µ –ª–∏ –¥–µ—Ç–µ–π"

–ü–†–ò–ú–ï–†–´ –ù–ï–ó–ê–í–ï–†–®–ï–ù–ù–´–• (—Ä–µ–¥–∫–∏–µ —Å–ª—É—á–∞–∏):
‚ùå "–ø–æ–¥—Å–∫–∞–∂–∏ –ø–æ–∂–∞–ª—É–π—Å—Ç–∞ –≥–¥–µ" - –æ–±—Ä—ã–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å–∏—Ç–µ–ª—å–Ω–æ–º —Å–ª–æ–≤–µ
‚ùå "—Ö–æ—á—É –∑–∞–ø–∏—Å–∞—Ç—å—Å—è –∫" - –æ–±—Ä—ã–≤ –Ω–∞ –ø—Ä–µ–¥–ª–æ–≥–µ  
‚ùå "—É –º–µ–Ω—è –±–æ–ª–∏—Ç" - –º–æ–∂–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å—Å—è ("—á—Ç–æ –∏–º–µ–Ω–Ω–æ")
‚ùå "–Ω—É–∂–Ω–æ —É–∑–Ω–∞—Ç—å –ø—Ä–æ" - –Ω–µ–∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è –º—ã—Å–ª—å
‚ùå "—è —Ö–æ—á—É —Å–∫–∞–∑–∞—Ç—å —á—Ç–æ" - —è–≤–Ω–æ –±—É–¥–µ—Ç –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ

–ü–†–ò–ú–ï–†–´ –° –ö–û–ù–¢–ï–ö–°–¢–û–ú –î–ò–ê–õ–û–ì–ê:
ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ö–∞–∫–∏–µ —É –≤–∞—Å —Å–∏–º–ø—Ç–æ–º—ã?
üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –±–æ–ª–∏—Ç –∂–∏–≤–æ—Ç
–¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: "–µ—â–µ –∏ —Ç–æ—à–Ω–æ—Ç–∞" ‚Üí COMPLETE (–¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –∫ —Å–∏–º–ø—Ç–æ–º–∞–º)

ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –ö –∫–∞–∫–æ–º—É –≤—Ä–∞—á—É —Ö–æ—Ç–∏—Ç–µ –∑–∞–ø–∏—Å–∞—Ç—å—Å—è?
üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: —Ö–æ—á—É –∫ –≤—Ä–∞—á—É
–¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: "–∫ —Ç–µ—Ä–∞–ø–µ–≤—Ç—É" ‚Üí COMPLETE (–æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å)

üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: –Ω—É–∂–Ω–∞ —Å–ø—Ä–∞–≤–∫–∞
ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: –î–ª—è —á–µ–≥–æ –Ω—É–∂–Ω–∞ —Å–ø—Ä–∞–≤–∫–∞?
–¢–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ: "–¥–ª—è —Ä–∞–±–æ—Ç—ã" ‚Üí COMPLETE (–æ—Ç–≤–µ—Ç –Ω–∞ —É—Ç–æ—á–Ω–µ–Ω–∏–µ)

–ö–†–ò–¢–ï–†–ò–ò –î–õ–Ø COMPLETE:
- –ï—Å—Ç—å –∑–∞–∫–æ–Ω—á–µ–Ω–Ω–∞—è –º—ã—Å–ª—å (–ø–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ —Ö–æ—á–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å)
- –í–æ–ø—Ä–æ—Å —Å–æ–¥–µ—Ä–∂–∏—Ç –≤—Å–µ –∫–ª—é—á–µ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã  
- –ú–æ–∂–Ω–æ –¥–∞—Ç—å –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç
- –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–∞—è –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏—è

–í–†–ï–ú–Ø –û–ñ–ò–î–ê–ù–ò–Ø:
- COMPLETE: 0 —Å–µ–∫—É–Ω–¥ (–æ—Ç–≤–µ—á–∞–µ–º —Å—Ä–∞–∑—É)
- INCOMPLETE: 5 —Å–µ–∫—É–Ω–¥ (–∂–¥–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è)

–ö–†–ê–¢–ö–ò–ï –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–ò–Ø:
–°–æ–æ–±—â–µ–Ω–∏—è, —Å–æ—Å—Ç–æ—è—â–∏–µ –¢–û–õ–¨–ö–û –∏–∑ –∫–æ—Ä–æ—Ç–∫–∏—Ö —Å–ª–æ–≤ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –∏–ª–∏ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö —ç–º–æ–¥–∑–∏ ("–¥–∞", "–æ–∫", "—Å—É–ø–µ—Ä", "üëç" –∏ –¥—Ä.), –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –º–µ–Ω–µ–µ —á–µ–º —á–µ—Ä–µ–∑ 15 —Å–µ–∫—É–Ω–¥ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞, —Å—á–∏—Ç–∞—é—Ç—Å—è INCOMPLETE –∏ –Ω–µ —Ç—Ä–µ–±—É—é—Ç –æ—Ç–≤–µ—Ç–∞.

–ü–†–ò–ú–ï–†–´ –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–ò–ô (INCOMPLETE):
‚ùå "–¥–∞"
‚ùå "–æ–∫"
‚ùå "—Å—É–ø–µ—Ä"
‚ùå "üëç"

"""

    def _create_cache_key(self, context: MessageContext) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –∫–ª—é—á –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
        return f"{context.user_id}:{hash(context.current_message + str(context.previous_messages[-3:]))}"
    
    def _clean_cache(self):
        """–û—á–∏—â–∞–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏ –∫—ç—à–∞"""
        current_time = time.time()
        expired_keys = [
            key for key, (_, timestamp) in self._analysis_cache.items()
            if current_time - timestamp > self._cache_ttl
        ]
        for key in expired_keys:
            del self._analysis_cache[key]
    
    async def analyze_message_completeness(self, context: MessageContext) -> MessageAnalysis:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è
        
        Args:
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            MessageAnalysis: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
        """

        cache_key = self._create_cache_key(context)
        self._clean_cache()
        
        if cache_key in self._analysis_cache:
            cached_analysis, _ = self._analysis_cache[cache_key]
            logger.debug(f"–í–æ–∑–≤—Ä–∞—â–µ–Ω –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è {context.user_id}")
            return cached_analysis
        
        try:
            analysis_request = self._prepare_analysis_request(context)
            

            chain = self.prompt_template | self.llm
            
            
            start_time = time.time()
            analysis_result = await chain.ainvoke({"analysis_request": analysis_request})
            analysis_time = time.time() - start_time
            
            logger.info(f"–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è {context.user_id}: {analysis_result.status} "
                       f"(—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis_result.confidence:.2f}, –≤—Ä–µ–º—è: {analysis_time:.2f}s)")
            
            
            self._analysis_cache[cache_key] = (analysis_result, time.time())
            
            return analysis_result
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        
            return MessageAnalysis(
                status=CompletenessStatus.COMPLETE,
                confidence=0.5,
                reasoning=f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}. –ü—Ä–∏ –æ—à–∏–±–∫–µ –ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º –æ—Ç–≤–µ—á–∞—Ç—å.",
                suggested_wait_time=0.0,
                indicators=["analysis_error", "fallback_complete"]
            )
    
    def _prepare_analysis_request(self, context: MessageContext) -> str:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞"""
        request = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–æ–±—â–µ–Ω–∏–µ: "{context.current_message}"

–î–ª–∏–Ω–∞: {len(context.current_message)} —Å–∏–º–≤–æ–ª–æ–≤
–°–ª–æ–≤: {len(context.current_message.split())}"""

        if context.previous_messages:
            history_text = "\n".join([
                msg for msg in context.previous_messages[-5:]  
            ])
            request += f"""

–ö–û–ù–¢–ï–ö–°–¢ –î–ò–ê–õ–û–ì–ê (–ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è):
{history_text}

–£—á–∏—Ç—ã–≤–∞–π –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –±–µ—Å–µ–¥—ã –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ —Ç–µ–∫—É—â–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        
        request += "\n\n–í–µ—Ä–Ω–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏."
        
        return request

    def quick_heuristic_check(self, message: str) -> Optional[CompletenessStatus]:
        """
        –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—á–µ–≤–∏–¥–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None, –µ—Å–ª–∏ –Ω—É–∂–µ–Ω –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑ LLM
        """
        message = message.strip()
        
      
        if not message or len(message.strip()) == 0:
            return CompletenessStatus.INCOMPLETE
            
        if not any(c.isalnum() for c in message):
            return CompletenessStatus.INCOMPLETE
            
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞-–ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è (acknowledgements)
        normalized = re.sub(r"[^\w\s]", "", message.lower()).strip()
        ack_words = {
            "–¥–∞", "–æ–∫", "okay", "–æ–∫–µ–π", "—Å—É–ø–µ—Ä", "—Ö–æ—Ä–æ—à–æ",
            "–ø–æ–Ω—è—Ç–Ω–æ", "yep", "yeah", "sure", "got it", "roger"
        }
        if normalized in ack_words:
            return CompletenessStatus.INCOMPLETE

        if len(message) <= 2:
            return CompletenessStatus.INCOMPLETE
            
        
        return None 

_analyzer_instance: Optional[MessageCompletenessAnalyzer] = None


_message_accumulator: Dict[str, Dict[str, any]] = {}
ACCUMULATOR_TTL = 300  

def get_analyzer() -> MessageCompletenessAnalyzer:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    global _analyzer_instance
    if _analyzer_instance is None:
        raise RuntimeError("–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω. –í—ã–∑–æ–≤–∏—Ç–µ initialize_analyzer() –ø–µ—Ä–≤—ã–º.")
    return _analyzer_instance

def initialize_analyzer(openai_api_key: str, model_name: str = "o3-mini"):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞"""
    global _analyzer_instance
    _analyzer_instance = MessageCompletenessAnalyzer(openai_api_key, model_name)
    logger.info(f"–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å –º–æ–¥–µ–ª—å—é {model_name}")

def _clean_accumulator():
    """–û—á–∏—â–∞–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—è"""
    current_time = time.time()
    expired_keys = [
        user_id for user_id, data in _message_accumulator.items()
        if current_time - data['last_update'] > ACCUMULATOR_TTL
    ]
    for key in expired_keys:
        del _message_accumulator[key]
        logger.debug(f"–£–¥–∞–ª–µ–Ω —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {key}")

def add_message_to_accumulator(user_id: str, message: str) -> str:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∫–ª–µ–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    
    Args:
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        message: –ù–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è
        
    Returns:
        str: –°–∫–ª–µ–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ –≤—Å–µ—Ö —á–∞—Å—Ç–µ–π
    """
    _clean_accumulator()
    current_time = time.time()
    
    if user_id not in _message_accumulator:
    
        _message_accumulator[user_id] = {
            'accumulated_message': message,
            'last_update': current_time,
            'parts': [message],
            'part_count': 1
        }
        logger.info(f"–°–æ–∑–¥–∞–Ω –Ω–æ–≤—ã–π –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å –¥–ª—è {user_id}: '{message[:50]}...'")
    else:
        accumulator = _message_accumulator[user_id]
        
        separator = _get_smart_separator(accumulator['accumulated_message'], message)
        
        accumulator['accumulated_message'] += separator + message
        accumulator['last_update'] = current_time
        accumulator['parts'].append(message)
        accumulator['part_count'] += 1
        
        logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω–æ –∫ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—é {user_id} (—á–∞—Å—Ç—å {accumulator['part_count']}): '{message[:30]}...'")
        logger.debug(f"–°–∫–ª–µ–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è {user_id}: '{accumulator['accumulated_message'][:100]}...'")
    
    return _message_accumulator[user_id]['accumulated_message']

def get_accumulated_message(user_id: str) -> Optional[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –µ—Å—Ç—å"""
    _clean_accumulator()
    if user_id in _message_accumulator:
        return _message_accumulator[user_id]['accumulated_message']
    return None

def clear_accumulator(user_id: str):
    """–û—á–∏—â–∞–µ—Ç –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    if user_id in _message_accumulator:
        parts_count = _message_accumulator[user_id]['part_count']
        del _message_accumulator[user_id]
        logger.info(f"–û—á–∏—â–µ–Ω –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å –¥–ª—è {user_id} ({parts_count} —á–∞—Å—Ç–µ–π)")

def _get_smart_separator(existing: str, new: str) -> str:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —É–º–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –º–µ–∂–¥—É —á–∞—Å—Ç—è–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
    
    Args:
        existing: –°—É—â–µ—Å—Ç–≤—É—é—â–∞—è —á–∞—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è  
        new: –ù–æ–≤–∞—è —á–∞—Å—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è
        
    Returns:
        str: –ü–æ–¥—Ö–æ–¥—è—â–∏–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å
    """
  
    if existing.rstrip().endswith(('.', '!', '?', ':', ';')):
        return ' '
    
    
    if existing.rstrip().endswith(','):
        return ' '
    
    
    if new and new[0].islower():
        return ' '
    
    conjunctions = ['–∏', '–∞', '–Ω–æ', '–∏–ª–∏', '—á—Ç–æ', '–∫–∞–∫', '–∫–æ–≥–¥–∞', '–≥–¥–µ', '–ø–æ—Ç–æ–º—É —á—Ç–æ', '—Ç–∞–∫ –∫–∞–∫']
    for conj in conjunctions:
        if existing.rstrip().lower().endswith(conj):
            return ' '
    
    return ' '

async def analyze_message(
    message: str, 
    user_id: str, 
    previous_messages: Optional[List[str]] = None,
    time_since_last: Optional[float] = None
) -> MessageAnalysis:
    """
    –£–¥–æ–±–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
    
    Args:
        message: –¢–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        previous_messages: –ü—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        time_since_last: –í—Ä–µ–º—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        
    Returns:
        MessageAnalysis: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
    """
    analyzer = get_analyzer()
    
    quick_result = analyzer.quick_heuristic_check(message)
    if quick_result is not None:
        logger.debug(f"–ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è {user_id}: {quick_result}")
        
        confidence_map = {
            CompletenessStatus.INCOMPLETE: 0.85,
            CompletenessStatus.COMPLETE: 0.9
        }
        
        wait_time_map = {
            CompletenessStatus.INCOMPLETE: 5.0,
            CompletenessStatus.COMPLETE: 0.0
        }
        
        return MessageAnalysis(
            status=quick_result,
            confidence=confidence_map[quick_result],
            reasoning="–≠–≤—Ä–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑",
            suggested_wait_time=wait_time_map[quick_result],
            indicators=["heuristic_analysis"]
        )

    context = MessageContext(
        current_message=message,
        previous_messages=previous_messages or [],
        user_id=user_id,
        time_since_last_message=time_since_last
    )
    
    return await analyzer.analyze_message_completeness(context)

def get_history_via_langchain(tenant_id: str, user_id: str, limit: int = 15) -> List[str]:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ—Ç –∂–µ –ø–æ–¥—Ö–æ–¥, —á—Ç–æ –∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∞–≥–µ–Ω—Ç.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç LangChain TenantAwareRedisChatMessageHistory –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã data.content
    
    Args:
        tenant_id: ID —Ç–µ–Ω–∞–Ω—Ç–∞
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è  
        limit: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π
        
    Returns:
        List[str]: –°–ø–∏—Å–æ–∫ –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
    """
    try:
        # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≥–æ—Ç–æ–≤—ã–π –∫–ª–∞—Å—Å –∏–∑ redis_history
        from redis_history import TenantAwareRedisChatMessageHistory
        
        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∏—Å—Ç–æ—Ä–∏–∏ (—Ç–æ—Ç –∂–µ –ø–æ–¥—Ö–æ–¥ —á—Ç–æ —É –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∞–≥–µ–Ω—Ç–∞)
        chat_history = TenantAwareRedisChatMessageHistory(tenant_id=tenant_id, session_id=user_id)
        
        # –ü–æ–ª—É—á–∞–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ LangChain (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç data.content)
        messages = chat_history.messages
        logger.info(f"[LangChain –ò—Å—Ç–æ—Ä–∏—è] –ü–æ–ª—É—á–µ–Ω–æ {len(messages)} BaseMessage –æ–±—ä–µ–∫—Ç–æ–≤")
        
        if not messages:
            return []
        
        # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å–æ–≥–ª–∞—Å–Ω–æ –ª–∏–º–∏—Ç—É
        recent_messages = messages[-limit:] if len(messages) > limit else messages
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        formatted_messages = []
        for msg in recent_messages:
            # BaseMessage –∏–º–µ–µ—Ç –∞—Ç—Ä–∏–±—É—Ç—ã type –∏ content
            msg_type = getattr(msg, 'type', 'unknown')
            msg_content = getattr(msg, 'content', '').strip()
            
            if msg_content and len(msg_content) > 2:
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∞–≤—Ç–æ—Ä–∞
                author = "üë§ –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å" if msg_type == 'human' else "ü§ñ –ê—Å—Å–∏—Å—Ç–µ–Ω—Ç"
                formatted_message = f"{author}: {msg_content}"
                formatted_messages.append(formatted_message)
                logger.debug(f"[LangChain –ò—Å—Ç–æ—Ä–∏—è] ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ: '{formatted_message[:50]}...'")
            else:
                logger.debug(f"[LangChain –ò—Å—Ç–æ—Ä–∏—è] ‚ùå –ü—Ä–æ–ø—É—â–µ–Ω–æ: type='{msg_type}', len={len(msg_content)}")
        
        logger.info(f"[LangChain –ò—Å—Ç–æ—Ä–∏—è] –í–æ–∑–≤—Ä–∞—â–∞–µ–º {len(formatted_messages)} –æ—Ç—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π")
        return formatted_messages
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏—Å—Ç–æ—Ä–∏–∏ —á–µ—Ä–µ–∑ LangChain –¥–ª—è {tenant_id}:{user_id}: {e}", exc_info=True)
        return []

async def analyze_message_with_accumulation(
    message: str, 
    user_id: str, 
    previous_messages: Optional[List[str]] = None,
    time_since_last: Optional[float] = None
) -> Tuple[MessageAnalysis, str]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø—Ä–æ—Å—Ç—ã–º –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ–º —á–∞—Å—Ç–µ–π
    
    Args:
        message: –¢–µ–∫—Å—Ç –Ω–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è  
        previous_messages: –ü—Ä–µ–¥—ã–¥—É—â–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        time_since_last: –í—Ä–µ–º—è —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        
    Returns:
        Tuple[MessageAnalysis, str]: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
    """
    accumulated_message = add_message_to_accumulator(user_id, message)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤–µ—Å—å –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    analysis = await analyze_message(accumulated_message, user_id, previous_messages, time_since_last)
    
    # –ï—Å–ª–∏ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ - –æ—á–∏—â–∞–µ–º –Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if analysis.status == CompletenessStatus.COMPLETE:
        final_message = accumulated_message
        clear_accumulator(user_id)
        logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è {user_id} –∑–∞–≤–µ—Ä—à–µ–Ω–æ –ø–æ—Å–ª–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏—è: '{final_message[:100]}...'")
        return analysis, final_message
    
    # –ï—Å–ª–∏ –Ω–µ–ø–æ–ª–Ω–æ–µ - –æ—Å—Ç–∞–≤–ª—è–µ–º –≤ –Ω–∞–∫–æ–ø–∏—Ç–µ–ª–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–ª—è –æ–∂–∏–¥–∞–Ω–∏—è
    else:
        logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ –¥–ª—è {user_id} –Ω–µ–ø–æ–ª–Ω–æ–µ, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ: '{accumulated_message[:100]}...'")
        return analysis, accumulated_message

def should_wait_for_completion(analysis: MessageAnalysis) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –∂–¥–∞—Ç—å –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å–æ–æ–±—â–µ–Ω–∏—è
    
    Args:
        analysis: –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
        
    Returns:
        bool: True –µ—Å–ª–∏ –Ω—É–∂–Ω–æ –∂–¥–∞—Ç—å, False –µ—Å–ª–∏ –º–æ–∂–Ω–æ –æ—Ç–≤–µ—á–∞—Ç—å
    """
    if analysis.status == CompletenessStatus.COMPLETE:
        return False
        
    if analysis.status == CompletenessStatus.INCOMPLETE:
        return analysis.confidence > 0.7
        
    return False
        